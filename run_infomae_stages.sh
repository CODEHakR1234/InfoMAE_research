#!/bin/bash

# InfoMAE ë‹¨ê³„ë³„ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
# Stage 0: Warmup (encoder freeze, decoder í•™ìŠµìœ¼ë¡œ surprisal cache êµ¬ì¶•)
# Stage 1-3: ê° ê¸°ëŠ¥ ì‹¤í—˜ (Stage 0ì˜ checkpoint + cacheë¡œ ì‹œì‘í•˜ì—¬ ìì²´ cache ì—…ë°ì´íŠ¸)

set -e

# ê¸°ë³¸ ì„¤ì •
DATA_PATH="./data/imagenet100"
OUTPUT_DIR="./output_infomae"
MODEL="mae_vit_base_patch16"
SHARED_CACHE_DIR="./shared_surprisal_cache"

# ì¸ì íŒŒì‹±
STAGE=""
while [[ $# -gt 0 ]]; do
    case $1 in
        --stage)
            STAGE="$2"
            shift 2
            ;;
        *)
            echo "Unknown option: $1"
            echo "Usage: $0 [--stage STAGE_NUM]"
            echo "  STAGE_NUM: 0,1,2,3 or empty for all stages"
            exit 1
            ;;
    esac
done

# Stage 0 ì‹¤í–‰ ì¡°ê±´ í™•ì¸
if [ -z "$STAGE" ] || [ "$STAGE" = "0" ]; then
echo "========================================"
echo "Stage 0: Baseline (Encoder Freeze - Decoder Warmup)"
echo "========================================"
# ê³µìœ  surprisal cache ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ${SHARED_CACHE_DIR}

python main_pretrain.py \
    --data_path ${DATA_PATH} \
    --output_dir ${OUTPUT_DIR}/stage0 \
    --log_dir ${OUTPUT_DIR}/stage0 \
    --model ${MODEL} \
    --batch_size 64 \
    --epochs 50 \
    --warmup_epochs 10 \
    --blr 1e-3 \
    --weight_decay 0.05 \
    --mask_ratio 0.75 \
    --freeze_encoder \
    --use_epoch_cache \
    --cache_precision float32 \
    --resume ./checkpoints/mae_pretrain_vit_base.pth

# Stage 0 ì™„ë£Œ í›„ ì¤‘ê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "========================================"
echo "Stage 0 ì™„ë£Œ - ì¤‘ê°„ ê²°ê³¼ í…ŒìŠ¤íŠ¸"
echo "========================================"
if [ -f "${OUTPUT_DIR}/stage0/checkpoint-49.pth" ]; then
    ./test_pretrained.sh --ckpt ${OUTPUT_DIR}/stage0/checkpoint-49.pth --output ${OUTPUT_DIR}/stage0/test_stage0.png
    echo "âœ“ Stage 0 ì¤‘ê°„ ê²°ê³¼ ì €ì¥: ${OUTPUT_DIR}/stage0/test_stage0.png"
fi

# Stage 0ì˜ surprisal cacheë¥¼ ê³µìœ  ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
if [ -f "${OUTPUT_DIR}/stage0/surprisal_cache/surprisal_cache.pkl" ]; then
    cp ${OUTPUT_DIR}/stage0/surprisal_cache/surprisal_cache.pkl ${SHARED_CACHE_DIR}/
    echo "âœ“ Stage 0 surprisal cacheë¥¼ ê³µìœ  ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬"
fi
fi  # Stage 0 ì¢…ë£Œ

# Stage 1: SWA ì‹¤í—˜ (Stage 0 cache ê¸°ë°˜)
if [ -z "$STAGE" ] || [ "$STAGE" = "1" ]; then
echo "========================================"
echo "Stage 1: SWA ì‹¤í—˜ (Stage 0 cache ê¸°ë°˜)"
echo "========================================"
# ê³µìœ  surprisal cacheë¥¼ stage1ì˜ cache ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
mkdir -p ${OUTPUT_DIR}/stage1/surprisal_cache
if [ -f "${SHARED_CACHE_DIR}/surprisal_cache.pkl" ]; then
    cp ${SHARED_CACHE_DIR}/surprisal_cache.pkl ${OUTPUT_DIR}/stage1/surprisal_cache/
    echo "âœ“ ê³µìœ  surprisal cacheë¥¼ Stage 1ì— ë³µì‚¬"
fi

python main_pretrain.py \
    --data_path ${DATA_PATH} \
    --output_dir ${OUTPUT_DIR}/stage1 \
    --log_dir ${OUTPUT_DIR}/stage1 \
    --model ${MODEL} \
    --batch_size 64 \
    --epochs 100 \
    --warmup_epochs 10 \
    --blr 1e-3 \
    --weight_decay 0.05 \
    --mask_ratio 0.75 \
    --use_surprisal_attention \
    --surprisal_lambda 1.0 \
    --resume ${OUTPUT_DIR}/stage0/checkpoint-49.pth

# Stage 1 ì™„ë£Œ í›„ ì¤‘ê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "========================================"
echo "Stage 1 ì™„ë£Œ - ì¤‘ê°„ ê²°ê³¼ í…ŒìŠ¤íŠ¸"
echo "========================================"
if [ -f "${OUTPUT_DIR}/stage1/checkpoint-99.pth" ]; then
    ./test_pretrained.sh --ckpt ${OUTPUT_DIR}/stage1/checkpoint-99.pth --output ${OUTPUT_DIR}/stage1/test_stage1.png
    echo "âœ“ Stage 1 ì¤‘ê°„ ê²°ê³¼ ì €ì¥: ${OUTPUT_DIR}/stage1/test_stage1.png"
fi
fi  # Stage 1 ì¢…ë£Œ

# Stage 2: Adaptive ì‹¤í—˜ (Stage 0 cache ê¸°ë°˜)
if [ -z "$STAGE" ] || [ "$STAGE" = "2" ]; then
echo "========================================"
echo "Stage 2: Adaptive ì‹¤í—˜ (Stage 0 cache ê¸°ë°˜)"
echo "========================================"
# ê³µìœ  surprisal cacheë¥¼ stage2ì˜ cache ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
mkdir -p ${OUTPUT_DIR}/stage2/surprisal_cache
if [ -f "${SHARED_CACHE_DIR}/surprisal_cache.pkl" ]; then
    cp ${SHARED_CACHE_DIR}/surprisal_cache.pkl ${OUTPUT_DIR}/stage2/surprisal_cache/
    echo "âœ“ ê³µìœ  surprisal cacheë¥¼ Stage 2ì— ë³µì‚¬"
fi

python main_pretrain.py \
    --data_path ${DATA_PATH} \
    --output_dir ${OUTPUT_DIR}/stage2 \
    --log_dir ${OUTPUT_DIR}/stage2 \
    --model ${MODEL} \
    --batch_size 64 \
    --epochs 100 \
    --warmup_epochs 10 \
    --blr 1e-3 \
    --weight_decay 0.05 \
    --mask_ratio 0.75 \
    --use_surprisal_attention \
    --surprisal_lambda 1.0 \
    --adaptive_masking \
    --use_epoch_cache \
    --cache_precision float32 \
    --adaptive_alpha 0.0 \
    --adaptive_gamma 1.0 \
    --beta_ib 0.02 \
    --resume ${OUTPUT_DIR}/stage0/checkpoint-49.pth

# Stage 2 ì™„ë£Œ í›„ ì¤‘ê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "========================================"
echo "Stage 2 ì™„ë£Œ - ì¤‘ê°„ ê²°ê³¼ í…ŒìŠ¤íŠ¸"
echo "========================================"
if [ -f "${OUTPUT_DIR}/stage2/checkpoint-99.pth" ]; then
    ./test_pretrained.sh --ckpt ${OUTPUT_DIR}/stage2/checkpoint-99.pth --output ${OUTPUT_DIR}/stage2/test_stage2.png
    echo "âœ“ Stage 2 ì¤‘ê°„ ê²°ê³¼ ì €ì¥: ${OUTPUT_DIR}/stage2/test_stage2.png"
fi
fi  # Stage 2 ì¢…ë£Œ

# Stage 3: Full ì‹¤í—˜ (Stage 0 cache ê¸°ë°˜)
if [ -z "$STAGE" ] || [ "$STAGE" = "3" ]; then
echo "========================================"
echo "Stage 3: Full ì‹¤í—˜ (Stage 0 cache ê¸°ë°˜)"
echo "========================================"
# ê³µìœ  surprisal cacheë¥¼ stage3ì˜ cache ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
mkdir -p ${OUTPUT_DIR}/stage3/surprisal_cache
if [ -f "${SHARED_CACHE_DIR}/surprisal_cache.pkl" ]; then
    cp ${SHARED_CACHE_DIR}/surprisal_cache.pkl ${OUTPUT_DIR}/stage3/surprisal_cache/
    echo "âœ“ ê³µìœ  surprisal cacheë¥¼ Stage 3ì— ë³µì‚¬"
fi

python main_pretrain.py \
    --data_path ${DATA_PATH} \
    --output_dir ${OUTPUT_DIR}/stage3 \
    --log_dir ${OUTPUT_DIR}/stage3 \
    --model ${MODEL} \
    --batch_size 64 \
    --epochs 100 \
    --warmup_epochs 10 \
    --blr 1e-3 \
    --weight_decay 0.05 \
    --mask_ratio 0.75 \
    --use_surprisal_attention \
    --surprisal_lambda 1.0 \
    --adaptive_masking \
    --use_epoch_cache \
    --cache_precision float32 \
    --adaptive_alpha 0.0 \
    --adaptive_gamma 1.0 \
    --beta_ib 0.02 \
    --resume ${OUTPUT_DIR}/stage0/checkpoint-49.pth

# Stage 3 ì™„ë£Œ í›„ ìµœì¢… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "========================================"
echo "Stage 3 ì™„ë£Œ - ìµœì¢… ê²°ê³¼ í…ŒìŠ¤íŠ¸"
echo "========================================"
if [ -f "${OUTPUT_DIR}/stage3/checkpoint-99.pth" ]; then
    ./test_pretrained.sh --ckpt ${OUTPUT_DIR}/stage3/checkpoint-99.pth --output ${OUTPUT_DIR}/stage3/test_stage3_final.png
    echo "âœ“ Stage 3 ìµœì¢… ê²°ê³¼ ì €ì¥: ${OUTPUT_DIR}/stage3/test_stage3_final.png"
fi

echo "========================================"
echo "InfoMAE ë‹¨ê³„ë³„ í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
echo ""
echo "ğŸ“ Checkpoint íŒŒì¼ë“¤:"
echo "  Stage 0 (Warmup): ${OUTPUT_DIR}/stage0/checkpoint-49.pth"
echo "  Stage 1 (SWA): ${OUTPUT_DIR}/stage1/checkpoint-99.pth"
echo "  Stage 2 (Adaptive): ${OUTPUT_DIR}/stage2/checkpoint-99.pth"
echo "  Stage 3 (Full): ${OUTPUT_DIR}/stage3/checkpoint-99.pth"
echo ""
echo "ğŸ–¼ï¸  ì‹œê°í™” ê²°ê³¼ë“¤:"
echo "  Stage 0: ${OUTPUT_DIR}/stage0/test_stage0.png"
echo "  Stage 1: ${OUTPUT_DIR}/stage1/test_stage1.png"
echo "  Stage 2: ${OUTPUT_DIR}/stage2/test_stage2.png"
echo "  Stage 3: ${OUTPUT_DIR}/stage3/test_stage3_final.png"
echo ""
echo "ğŸ“Š TensorBoard ë¡œê·¸:"
echo "  tensorboard --logdir ${OUTPUT_DIR}/stage0"
echo "  tensorboard --logdir ${OUTPUT_DIR}/stage1"
echo "  tensorboard --logdir ${OUTPUT_DIR}/stage2"
echo "  tensorboard --logdir ${OUTPUT_DIR}/stage3"
echo "========================================"
fi  # Stage 3 ì¢…ë£Œ
